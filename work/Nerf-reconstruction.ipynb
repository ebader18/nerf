{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257860de-71ad-4386-88bd-fc945e3bc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import get_rays\n",
    "from rendering import rendering\n",
    "from model import Voxels, Nerf\n",
    "from ml_helpers import training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922e325-8976-4a36-88aa-908cbe4d3953",
   "metadata": {},
   "source": [
    "# Hyperparameters / Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e62ab8-9524-48b6-a646-01b27c9a3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 18\n",
    "batch_size = 1024   # 4096 used in paper, 1024 used in code\n",
    "nb_epochs = 10\n",
    "lr = 1e-3   # 5e-4 used in paper, 1e-3 used in code\n",
    "#final_lr = 5e-5\n",
    "gamma = .5\n",
    "#gamma = (final_lr / lr) ** (1 / (nb_epochs - 1))\n",
    "nb_bins = 100   # 128 used in paper, 100 used in code\n",
    "\n",
    "#dataset = 'fox'\n",
    "dataset = 'helmet/400x400'\n",
    "datapath = f'C:/_sw/eb_python/deep_learning/_dataset/NeRF/images/{dataset}'\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "o, d, target_px_values = get_rays(datapath, mode='train')\n",
    "dataloader = DataLoader(torch.cat((torch.from_numpy(o).reshape(-1, 3).type(torch.float),\n",
    "                                   torch.from_numpy(d).reshape(-1, 3).type(torch.float),\n",
    "                                   torch.from_numpy(target_px_values).reshape(-1, 3).type(torch.float)), dim=1),\n",
    "                                   batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#dataloader_warmup = DataLoader(torch.cat((torch.from_numpy(o).reshape(90, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float),\n",
    "#                               torch.from_numpy(d).reshape(90, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float),\n",
    "#                               torch.from_numpy(target_px_values).reshape(90, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float)), dim=1),\n",
    "#                               batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloader_warmup = DataLoader(torch.cat((torch.from_numpy(o).reshape(936, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float),\n",
    "                               torch.from_numpy(d).reshape(936, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float),\n",
    "                               torch.from_numpy(target_px_values).reshape(936, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float)), dim=1),\n",
    "                               batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#test_o, test_d, test_target_px_values = get_rays(datapath, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a46f8",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d917ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse2psnr(mse):\n",
    "    return 20 * np.log10(1 / np.sqrt(mse))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, o, d, tn, tf, nb_bins=100, chunk_size=10, H=400, W=400, target=None):\n",
    "    \n",
    "    o = o.chunk(chunk_size)\n",
    "    d = d.chunk(chunk_size)\n",
    "    \n",
    "    image = []\n",
    "    for o_batch, d_batch in zip(o, d):\n",
    "        img_batch = rendering(model, o_batch, d_batch, tn, tf, nb_bins=nb_bins, device=o_batch.device)\n",
    "        image.append(img_batch) # N, 3\n",
    "    image = torch.cat(image)\n",
    "    image = image.reshape(H, W, 3).cpu().numpy()\n",
    "    \n",
    "    if target is not None:\n",
    "        mse = ((image - target)**2).mean()\n",
    "        psnr = mse2psnr(mse)\n",
    "    \n",
    "    if target is not None: \n",
    "        return image, mse, psnr\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5029a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowTrainResults(training_loss, title):\n",
    "    plt.plot(training_loss)\n",
    "    plt.ylim(0.001, 1)\n",
    "    plt.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "    plt.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title(f'{title} - Min/max: {np.min(training_loss):.4f}/{np.max(training_loss):.2f}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowTestImages(model, tn, tf, device, title):\n",
    "    col, row = 4, 13\n",
    "    fig, axs = plt.subplots(row, col, figsize=(20, 65))\n",
    "    for r in range(row):\n",
    "        for c in range(col):\n",
    "            img_idx = 72 * r + 18 * c\n",
    "            img, mse, psnr = test(model, torch.from_numpy(o[img_idx]).to(device).float(), torch.from_numpy(d[img_idx]).to(device).float(),\n",
    "                    tn, tf, nb_bins=100, chunk_size=10, target=target_px_values[img_idx].reshape(400, 400, 3))\n",
    "            axs[r, c].imshow(img, cmap='gray')\n",
    "            axs[r, c].set_title(f'Image {img_idx}, PSNR: {psnr:.1f}')\n",
    "            axs[r, c].axis('off')  # Hide axis for a cleaner look\n",
    "\n",
    "    plt.tight_layout()  # Adjust subplots to fit in the figure area\n",
    "    fig.suptitle(title, fontsize=16, y=1.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc6284-ff38-4a9d-a914-7cd8ff9163fb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd96eec-e258-469d-8781-da1dc2bd1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "#tn, tf = 8., 12.\n",
    "tn, tf = 2., 6.\n",
    "\n",
    "model = Nerf(hidden_dim=128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10], gamma=gamma)\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "training_loss = training(model, optimizer, scheduler, tn, tf, nb_bins, 1, dataloader_warmup, device=device)\n",
    "ShowTrainResults(training_loss, \"Training Loss - Warmup\")\n",
    "ShowTestImages(model, tn, tf, device, \"Test images for wamrup dataloader\")\n",
    "\n",
    "training_loss = training(model, optimizer, scheduler, tn, tf, nb_bins, nb_epochs, dataloader, device=device)\n",
    "ShowTrainResults(training_loss, \"Training Loss for last epoch\")\n",
    "ShowTestImages(model, tn, tf, device, \"Test images for last epoch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
